import os
import json
from fastapi import FastAPI, Request
from telegram import Update, Bot
from telegram.ext import Application, ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters
from langchain_openai import OpenAIEmbeddings 
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
import openai
from contextlib import asynccontextmanager

# üîê –¢–æ–∫–µ–Ω–∏
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
WEBHOOK_URL = os.getenv("WEBHOOK_URL")

openai.api_key = OPENAI_API_KEY
bot = Bot(BOT_TOKEN)

# üéØ System prompt
SYSTEM_PROMPT = (
    "–¢–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç-–ø—Ä–æ–¥–∞–≤–µ—Ü—å ROZETKA. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –∫–æ—Ä–æ—Ç–∫–æ, —á—ñ—Ç–∫–æ, –±–µ–∑ –≤–∏–≥–∞–¥–æ–∫, —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é. "
    "–ù–∞ –æ—Å–Ω–æ–≤—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó —Ç–æ–≤–∞—Ä—É –∑ –±–∞–∑–∏ –∑–Ω–∞–Ω—å, –Ω–∞–¥–∞–π –ø–µ—Ä–µ–ª—ñ–∫ —Å–µ—Ä–≤—ñ—Å—ñ–≤ SUPPORT.UA, —è–∫—ñ –º–æ–∂–Ω–∞ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏."
)

# üìö –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –±–∞–∑–∏ –∑–Ω–∞–Ω—å
with open("knowledge_base.json", encoding="utf-8") as f:
    raw_data = json.load(f)

documents = []
for entry in raw_data:
    category = entry.get("category", "")
    keywords = ", ".join(entry.get("keywords", []))
    services = "\n".join([f"- {s['name']}: {s['desc']}" for s in entry.get("services", [])])
    content = f"–ö–∞—Ç–µ–≥–æ—Ä—ñ—è: {category}\n–ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞: {keywords}\n–°–µ—Ä–≤—ñ—Å–∏:\n{services}"
    documents.append(Document(page_content=content))

vectorstore = FAISS.from_documents(documents, OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY))

# üì¶ Telegram Application
application: Application = ApplicationBuilder().token(BOT_TOKEN).build()

# üì¨ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤—ñ—Ç! –ù–∞–ø–∏—à–∏ –Ω–∞–∑–≤—É —Ç–æ–≤–∞—Ä—É, —ñ —è –ø—ñ–¥–∫–∞–∂—É —Å–µ—Ä–≤—ñ—Å–∏ SUPPORT.UA.")

# üß† –û–±—Ä–æ–±–∫–∞ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
async def handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.message.text.strip()

    try:
        docs = vectorstore.similarity_search(query, k=3)
        context_text = "\n".join(doc.page_content for doc in docs)

        response = openai.ChatCompletion.create(  # ‚úÖ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –≤–∏–∫–ª–∏–∫
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT + "\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n" + context_text},
                {"role": "user", "content": query}
            ]
        )
        reply = response["choices"][0]["message"]["content"]
        await update.message.reply_text(reply)

    except Exception as e:
        await update.message.reply_text("–í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞. –°–ø—Ä–æ–±—É–π —â–µ —Ä–∞–∑ –ø—ñ–∑–Ω—ñ—à–µ.")
        print(f"Error: {e}")

application.add_handler(CommandHandler("start", start))
application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle))

# üõ† Lifespan –¥–ª—è FastAPI
@asynccontextmanager
async def lifespan(app: FastAPI):
    await bot.set_webhook(url=WEBHOOK_URL)
    print("‚úÖ Webhook –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    yield

# ü§ñ FastAPI –∑ lifespan
app = FastAPI(lifespan=lifespan)

# üõ° –û–±—Ä–æ–±–Ω–∏–∫ –¥–ª—è –∫–æ—Ä–µ–Ω—è (—â–æ–± –Ω–µ –±—É–ª–æ 404 –≤ –ª–æ–≥–∞—Ö)
@app.get("/")
async def root():
    return {"message": "–ë–æ—Ç –ø—Ä–∞—Ü—é—î! Webhook –Ω–∞ /webhook"}

# üì¨ –û–±—Ä–æ–±–∫–∞ Telegram –≤–µ–±—Ö—É–∫–∞
@app.post("/webhook")
async def telegram_webhook(req: Request):
    data = await req.json()
    update = Update.de_json(data, bot)
    await application.update_queue.put(update)
    return {"ok": True}


